# Delirium QLoRA DPO Configuration
# Copy this file to .env and customize the values

# Dataset Configuration
DATASETS_DIR=data
CACHE_DIR=cache
HF_DATASETS_CACHE=${CACHE_DIR}/huggingface/datasets
HF_MODELS_CACHE=${CACHE_DIR}/huggingface/models

# Training Configuration
MODELS_DIR=models
LOGS_DIR=logs

# Hugging Face Configuration (optional)
# HF_TOKEN=your_hugging_face_token_here

# Weights & Biases Configuration (optional)
# WANDB_PROJECT=delirium-dpo
# WANDB_ENTITY=your_wandb_username

# Memory and Performance
# PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
